# 作业二

## 1

0.54

## 2

(1)

### CBOW（Continuous Bag of Words）

- **目标**：根据上下文中的多个词（基于词袋模型）预测中心词。
- **输入**：上下文中的多个词。
- **输出**：预测中心词的概率分布。
- **特点**：  
  - 擅长处理大量上下文信息，能够更全面地捕捉上下文的语义。
  - 在训练过程中较为高效，因为它一次性处理多个上下文词来预测中心词。

### Skip-gram

- **目标**：根据给定的中心词预测其上下文词。
- **输入**：中心词的向量表示。
- **输出**：上下文词的概率分布。
- **特点**：  
  - 擅长捕捉单词的稀疏特征，能够更好地学习到单词的细粒度语义。
  - 适合小型数据集，但训练速度相对较慢，因为需要为每个中心词生成多个上下文预测。

(2)

pencil 和 book = $\frac{5}{6}$

## 3

$转移矩阵P=\left(\begin{matrix}
0 & \frac{1}{2} & 1 & 0 \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & \frac{1}{2} & 0 & 0 \\ \end{matrix}\right)\\
迭代后 [A, B, C, D]^T=[0.333, 0.222, 0.222, 0.222]^T
$

## 4

$
余弦相似度: = \frac{D1D2^T}{||D1||\;||D2||} = 0.76
欧氏距离: = \sqrt{(3-1)^2 + (0-2)^2 + (2-0)^2 + (5-4)^2 + (1-3)^2} = 4.12
Jaccard相似度: = \frac{6}{15} = 0.6
$

## 5

| 词项 | q0 | d1 | d2 | d3 | Q |
| --- | --- | --- | --- | --- | --- |
| Ariolimax | 0 | 1 | 0 | 0 | 0.375|
| Campus | 0 | 0 | 0 | 1 | 0|
| Cruz | 0 | 0 | 1 | 1 | 0.125|
| Mascot | 0 | 0 | 0 | 1 | 0|
| Santa | 0 | 0 | 1 | 1 | 0.125|
| banana | 1 | 1 | 1 | 0 | 1.75|
| columbianus | 0 | 1 | 0 | 0 | 0.375|
| mountains | 0 | 0 | 1 | 0 | 0.375|
| slug | 1 | 1 | 1 | 0 | 1.75|
